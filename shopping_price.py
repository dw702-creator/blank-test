import streamlit as st
from docx import Document
from docx.shared import Pt, Inches
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from io import BytesIO
import nltk
from nltk import pos_tag, word_tokenize
import random
import re
import math

# ---------- NLTK data (í•„ìš” ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ) ----------
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt', quiet=True)

try:
    nltk.data.find('taggers/averaged_perceptron_tagger')
except LookupError:
    nltk.download('averaged_perceptron_tagger', quiet=True)

# ---------- POS ê·¸ë£¹ ë§¤í•‘ ----------
POS_GROUPS = {
    "ë™ì‚¬": {"VB", "VBD", "VBG", "VBN", "VBP", "VBZ"},
    "ëª…ì‚¬": {"NN", "NNS", "NNP", "NNPS"},
    "í˜•ìš©ì‚¬": {"JJ", "JJR", "JJS"},
    "ë¶€ì‚¬": {"RB", "RBR", "RBS"},
}

# ---------- í—¬í¼: í† í° í›„ë³´ íŒë‹¨ ----------
TOKEN_CANDIDATE_RE = re.compile(r"[A-Za-z0-9\uac00-\ud7a3]+")  # ì•ŒíŒŒë²³, ìˆ«ì, í•œê¸€ í¬í•¨

def is_candidate_token(tok):
    return bool(TOKEN_CANDIDATE_RE.search(tok))

# ---------- í—¬í¼: ë¬¸ì¥ í† í°í™” ë° ì¬ì¡°ë¦½ ----------
def tokenize_preserve_spacing(text):
    """
    word_tokenizeë¡œ í† í°í™” í›„, punctuation ë¶™ì„ ê·œì¹™ì„ ì ìš©í•´ ë‹¤ì‹œ ë¬¸ìì—´ì„ ì¡°ë¦½í•˜ê¸° ì‰¬ìš´ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    ë°˜í™˜: tokens (list)
    """
    tokens = word_tokenize(text)
    return tokens

def assemble_tokens(tokens):
    """
    í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³µì›.
    punctuation(êµ¬ë‘ì ) ì•ì—ëŠ” ê³µë°± ì—†ì´ ë¶™ì´ê³ , ê·¸ ì™¸ì—ëŠ” ê³µë°±ì„ ë„£ìŒ.
    """
    out = ""
    for i, t in enumerate(tokens):
        if i == 0:
            out += t
            continue
        if re.fullmatch(r"[^\w\s]", t):  # punctuation
            out += t
        else:
            # ì´ì „ì´ opening quote? (ê°„ë‹¨ ì²˜ë¦¬) í•­ìƒ ê³µë°± ì¶”ê°€
            out += " " + t
    return out

# ---------- ë¬¸ë‹¨ í…Œë‘ë¦¬ ì ìš© ----------
def set_paragraph_border(paragraph):
    p = paragraph._p
    pPr = p.get_or_add_pPr()
    # ê¸°ì¡´ pBdr ì œê±° (ì¤‘ë³µ ë°©ì§€)
    existing = pPr.find(qn('w:pBdr'))
    if existing is not None:
        pPr.remove(existing)
    pBdr = OxmlElement('w:pBdr')
    for border_name in ['top', 'left', 'bottom', 'right']:
        border = OxmlElement(f'w:{border_name}')
        border.set(qn('w:val'), 'single')
        border.set(qn('w:sz'), '4')
        border.set(qn('w:space'), '4')
        border.set(qn('w:color'), '000000')
        pBdr.append(border)
    pPr.append(pBdr)

# ---------- í°íŠ¸ ì„¤ì • (run ë‹¨ìœ„) ----------
def set_runs_font(paragraph, size_pt=11, bold=False):
    for run in paragraph.runs:
        run.font.size = Pt(size_pt)
        run.font.bold = bold

def set_cell_font(cell, size_pt=11, bold=False):
    for p in cell.paragraphs:
        for r in p.runs:
            r.font.size = Pt(size_pt)
            r.font.bold = bold

# ---------- í•µì‹¬: ë¬¸ì„œ ìƒì„± í•¨ìˆ˜ ----------
def process_docx_with_answer(file_like, pos_choice, blank_ratio_fraction):
    """
    file_like: ì—…ë¡œë“œëœ .docx íŒŒì¼ ê°ì²´
    pos_choice: "ì „ì²´" ë˜ëŠ” "ë™ì‚¬"/"ëª…ì‚¬"/"í˜•ìš©ì‚¬"/"ë¶€ì‚¬"
    blank_ratio_fraction: 0~1 ì‚¬ì´ (ì˜ˆ: 0.2)
    """
    src = Document(file_like)
    dst = Document()

    # ì—¬ë°± ì„¤ì •
    for section in dst.sections:
        section.top_margin = Inches(0.6)
        section.bottom_margin = Inches(0.6)
        section.left_margin = Inches(0.6)
        section.right_margin = Inches(0.6)

    # ìƒë‹¨ í—¤ë” í…Œì´ë¸” (2x4)
    header = dst.add_table(rows=2, cols=4)
    header.style = 'Table Grid'
    header.autofit = True

    # ì²« ì¤„ ë¼ë²¨ë“¤
    header.cell(0,0).text = "ë°˜"
    header.cell(0,1).text = ""
    header.cell(0,2).text = "ì´ë¦„"
    header.cell(0,3).text = ""
    # ë‘˜ì§¸ ì¤„
    header.cell(1,0).text = "ì ìˆ˜"
    header.cell(1,1).text = ""
    header.cell(1,2).text = "ì„ ìƒë‹˜ í™•ì¸"
    header.cell(1,3).text = ""

    # í°íŠ¸ ì¡°ì •
    for r in header.rows:
        for c in r.cells:
            set_cell_font(c, size_pt=11, bold=True)

    dst.add_paragraph("")  # ê°„ê²©

    # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìˆœíšŒí•˜ë©° ë¬¸ì œ ìƒì„±
    answer_map = {}   # { ë²ˆí˜¸: word }
    next_blank_num = 1

    for para in src.paragraphs:
        orig_text = para.text.strip()
        if not orig_text:
            dst.add_paragraph("")
            continue

        tokens = tokenize_preserve_spacing(orig_text)
        # POS íƒœê¹… (pos_tag expects list of tokens)
        try:
            tagged = pos_tag(tokens)
        except Exception:
            # ë§Œì•½ ì˜¤ë¥˜ê°€ ë‚˜ë©´ ê°„ë‹¨ fallback: ëª¨ë“  í† í°ì— 'NN' ë¶€ì—¬
            tagged = [(t, 'NN') for t in tokens]

        # í›„ë³´ ì¸ë±ìŠ¤: POSê°€ ì„ íƒëœ ê·¸ë£¹ì— ì†í•˜ê³  í† í°ì´ ì•ŒíŒŒë²³/ìˆ«ì/í•œê¸€ í¬í•¨
        candidate_indices = []
        for i, (tok, tg) in enumerate(tagged):
            if is_candidate_token(tok):
                if pos_choice == "ì „ì²´":
                    candidate_indices.append(i)
                else:
                    if tg in POS_GROUPS.get(pos_choice, set()):
                        candidate_indices.append(i)

        # ë§Œì•½ ì„ íƒëœ í’ˆì‚¬ê°€ ë¬¸ë‹¨ì— í•˜ë‚˜ë„ ì—†ìœ¼ë©´(í›„ë³´ ì—†ìŒ), í›„ë³´ë¥¼ ì „ì²´ ë‹¨ì–´ë¡œ í™•ì¥
        if not candidate_indices:
            candidate_indices = [i for i, (tok, tg) in enumerate(tagged) if is_candidate_token(tok)]

        # ì„ íƒí•  ë¹ˆì¹¸ ìˆ˜
        n_candidates = len(candidate_indices)
        n_blanks = max(0, int(round(n_candidates * blank_ratio_fraction)))  # 0 í—ˆìš©
        # ë³´ì¥: n_blanks <= n_candidates
        n_blanks = min(n_blanks, n_candidates)

        chosen = []
        if n_blanks > 0 and n_candidates > 0:
            chosen = random.sample(candidate_indices, n_blanks)

        # ëŒ€ì²´í•  í† í° ë¦¬ìŠ¤íŠ¸ ë³µì‚¬
        out_tokens = list(tokens)

        # ì±„ìš°ê¸°: chosen ì¸ë±ìŠ¤ë“¤ì„ ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì²˜ë¦¬
        for idx in sorted(chosen):
            original_word = tokens[idx]
            # ì–¸ë”ë°” ê¸¸ì´: ì›ë˜ ë‹¨ì–´ ê¸¸ì´ (ìœ ë‹ˆì½”ë“œ ê¸¸ì´)
            underline = "_" * max(3, len(original_word))  # ìµœì†Œ ê¸¸ì´ 3ìœ¼ë¡œ í‘œì‹œ ê¹”ë”í•˜ê²Œ
            out_tokens[idx] = f"({next_blank_num}){underline}"
            answer_map[next_blank_num] = original_word
            next_blank_num += 1

        # assemble
        para_text = assemble_tokens(out_tokens)
        p = dst.add_paragraph(para_text)
        set_runs_font(p, size_pt=11, bold=False)
        set_paragraph_border(p)

    # --- ë‹µì§€ í˜ì´ì§€: ë§ˆì§€ë§‰ í˜ì´ì§€ì— ì¶”ê°€ ---
    dst.add_page_break()
    title = dst.add_paragraph("ğŸ“ ì •ë‹µì§€ (Answer Sheet)")
    set_runs_font(title, size_pt=13, bold=True)

    total_answers = len(answer_map)
    if total_answers == 0:
        dst.add_paragraph("ì •ë‹µ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # 3ì—´ (columns) êµ¬ì„±, ì—´ì„ ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ ì±„ìš°ê¸°
        num_cols = 3
        rows_needed = math.ceil(total_answers / num_cols)
        answers_table = dst.add_table(rows=rows_needed, cols=num_cols)
        answers_table.style = "Table Grid"

        # Fill column by column, top to bottom
        # mapping: for col in 0..num_cols-1:
        #   for row in 0..rows_needed-1:
        #       idx = col*rows_needed + row + 1
        for col in range(num_cols):
            for row in range(rows_needed):
                idx = col * rows_needed + row + 1
                cell = answers_table.cell(row, col)
                if idx <= total_answers:
                    cell.text = f"{idx}. {answer_map[idx]}"
                    set_cell_font(cell, size_pt=11, bold=False)
                else:
                    cell.text = ""
    # ë©”ëª¨ë¦¬ì— ì €ì¥
    out = BytesIO()
    dst.save(out)
    out.seek(0)
    return out

# ---------------- Streamlit UI ----------------
st.set_page_config(page_title="ì—°ì„¸ì˜ì–´í•™ì› - ìë™ ë¹ˆì¹¸ ì¶œì œê¸°", layout="wide")
st.title("ğŸ“˜ ì—°ì„¸ì˜ì–´í•™ì› ìë™ ë¹ˆì¹¸ ì¶œì œê¸°")
st.markdown("ì—…ë¡œë“œí•œ Word(.docx)ì—ì„œ íŠ¹ì • í’ˆì‚¬ë§Œ ì„ íƒí•˜ì—¬ ëœë¤ìœ¼ë¡œ ë¹ˆì¹¸ì„ ìƒì„±í•˜ê³ , ë§ˆì§€ë§‰ í˜ì´ì§€ì— ì •ë‹µì§€ë¥¼ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.")

with st.sidebar:
    st.header("ì„¤ì •")
    pos_choice = st.selectbox("1) ë¹ˆì¹¸ìœ¼ë¡œ ë§Œë“¤ í’ˆì‚¬ ì„ íƒ", ["ì „ì²´", "ë™ì‚¬", "ëª…ì‚¬", "í˜•ìš©ì‚¬", "ë¶€ì‚¬"])
    blank_pct = st.slider("2) ë¹ˆì¹¸ ë¹„ìœ¨ (%)", min_value=5, max_value=80, value=20, step=5,
                          help="ì„ íƒëœ í’ˆì‚¬ í›„ë³´ë“¤ ì¤‘ì—ì„œ ëª‡ %ë¥¼ ë¹ˆì¹¸ìœ¼ë¡œ ë§Œë“¤ì§€ ê²°ì •í•©ë‹ˆë‹¤.")
    st.write("")
    st.markdown("âš ï¸ í•œê¸€ ë¬¸ì„œëŠ” POS íƒœê¹… ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    preview_count = st.number_input("ë¯¸ë¦¬ë³´ê¸°: ë¬¸ë‹¨ ìˆ˜", min_value=1, max_value=20, value=5)

uploaded_file = st.file_uploader("Word(.docx) íŒŒì¼ ì—…ë¡œë“œ", type=["docx"])

if uploaded_file is not None:
    st.success("íŒŒì¼ ì—…ë¡œë“œ í™•ì¸ë¨.")
    # ë¯¸ë¦¬ë³´ê¸°
    try:
        preview_doc = Document(uploaded_file)
        st.subheader("ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ {} ë¬¸ë‹¨)".format(preview_count))
        shown = 0
        for p in preview_doc.paragraphs:
            text = p.text.strip()
            if not text:
                continue
            st.write(f"- {text}")
            shown += 1
            if shown >= preview_count:
                break
        uploaded_file.seek(0)
    except Exception as e:
        st.error("ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: ì—…ë¡œë“œëœ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ docx íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.exception(e)

    if st.button("ì‹œí—˜ì§€ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ"):
        try:
            uploaded_file.seek(0)
            out = process_docx_with_answer(uploaded_file, pos_choice, blank_pct / 100.0)
            st.success("ì‹œí—˜ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
            st.download_button(
                label="â¬‡ï¸ ì‹œí—˜ì§€(.docx) ë‹¤ìš´ë¡œë“œ (ë¬¸ì œ + ì •ë‹µì§€ í¬í•¨)",
                data=out,
                file_name="blank_test_with_answer.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        except Exception as e:
            st.error("ì‹œí—˜ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)
else:
    st.info("ë¨¼ì € Word(.docx) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
